{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1AMoQmkXZLP2M3XdqeMPKSYwX7M0lOxkw",
      "authorship_tag": "ABX9TyMEx4otWKlU+gL3UXiejKSa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tekleab15/N-gram-Language-Models/blob/main/N_gram_language_modelling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "PXzeNOTAbqKR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "import tensorflow as tf\n",
        "from collections import defaultdict\n",
        "import re, csv\n",
        "import pandas as pd\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "file_path = '/content/drive/MyDrive/Amharic_Corpus/Copy_of_GPAC.txt'\n",
        "\n",
        "# Text cleaning\n",
        "def clean_text(text):\n",
        "    return re.sub(r'[^ሀ-ፐ0-9\\s\\-\\.,!?]', '', text)\n",
        "def create_ngrams(tokens, n):\n",
        "    ngrams = zip(*[tokens[i:] for i in range(n)])\n",
        "    return [\" \".join(ngram) for ngram in ngrams]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J_CiZX9pcSCi",
        "outputId": "2f83411d-07db-41a4-eabb-d8f4ef8598c3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*1.1 Create n-grams for n=1, 2, 3, 4. You can show sample prints*"
      ],
      "metadata": {
        "id": "E2kFYUPEnbUy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize defaultdict for n-grams and their frequencies\n",
        "unigram_freq = defaultdict(int)\n",
        "bigram_freq = defaultdict(int)\n",
        "trigram_freq = defaultdict(int)\n",
        "fourgram_freq = defaultdict(int)\n",
        "\n",
        "# Generator function to read and clean lines from the file\n",
        "def read_and_clean_lines(file_path):\n",
        "    with open(file_path, 'r', encoding='utf-8') as f:\n",
        "        for line in f:\n",
        "            cleaned_line = clean_text(line)\n",
        "            tokens = cleaned_line.split()\n",
        "            if tokens:\n",
        "                yield tokens\n",
        "\n",
        "# Initialize defaultdict for n-grams and their frequencies\n",
        "unigram_freq = defaultdict(int)\n",
        "bigram_freq = defaultdict(int)\n",
        "trigram_freq = defaultdict(int)\n",
        "fourgram_freq = defaultdict(int)\n",
        "\n",
        "# Process the file using the generator function\n",
        "for tokens in read_and_clean_lines(file_path):\n",
        "    for ngram in create_ngrams(tokens, 1):\n",
        "        unigram_freq[ngram] += 1\n",
        "    for ngram in create_ngrams(tokens, 2):\n",
        "        bigram_freq[ngram] += 1\n",
        "    for ngram in create_ngrams(tokens, 3):\n",
        "        trigram_freq[ngram] += 1\n",
        "    for ngram in create_ngrams(tokens, 4):\n",
        "        fourgram_freq[ngram] += 1\n",
        "\n",
        "# Print sample n-grams with their frequencies\n",
        "print(\"         The first 10 n-gram representation: \")\n",
        "print(\"Unigram: \", list(unigram_freq.items())[:10])\n",
        "print(\"Bigram: \", list(bigram_freq.items())[:10])\n",
        "print(\"Trigram: \", list(trigram_freq.items())[:10])\n",
        "print(\"Fourgram: \", list(fourgram_freq.items())[:10])\n",
        "print(\"\\n\\n\\n\")"
      ],
      "metadata": {
        "id": "D8z3Jv5dRKHv",
        "outputId": "3884fdfe-6190-4f72-da42-e0079d595524",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         The first 10 n-gram representation: \n",
            "Unigram:  [('ምን', 43593), ('መሰላችሁ?', 942), ('አንባቢያን', 379), ('ኢትዮጵያ', 28031), ('በተደጋጋሚ', 4223), ('ጥሪው', 127), ('ደርሷት', 10), ('ልትታደመው', 1), ('ያልቻለችው', 24), ('የአለም', 1273)]\n",
            "Bigram:  [('ምን መሰላችሁ?', 328), ('መሰላችሁ? አንባቢያን', 1), ('አንባቢያን ኢትዮጵያ', 1), ('ኢትዮጵያ በተደጋጋሚ', 9), ('በተደጋጋሚ ጥሪው', 1), ('ጥሪው ደርሷት', 1), ('ደርሷት ልትታደመው', 1), ('ልትታደመው ያልቻለችው', 1), ('ያልቻለችው የአለም', 1), ('የአለም የእግር', 5)]\n",
            "Trigram:  [('ምን መሰላችሁ? አንባቢያን', 1), ('መሰላችሁ? አንባቢያን ኢትዮጵያ', 1), ('አንባቢያን ኢትዮጵያ በተደጋጋሚ', 1), ('ኢትዮጵያ በተደጋጋሚ ጥሪው', 1), ('በተደጋጋሚ ጥሪው ደርሷት', 1), ('ጥሪው ደርሷት ልትታደመው', 1), ('ደርሷት ልትታደመው ያልቻለችው', 1), ('ልትታደመው ያልቻለችው የአለም', 1), ('ያልቻለችው የአለም የእግር', 1), ('የአለም የእግር ኳስ', 5)]\n",
            "Fourgram:  [('ምን መሰላችሁ? አንባቢያን ኢትዮጵያ', 1), ('መሰላችሁ? አንባቢያን ኢትዮጵያ በተደጋጋሚ', 1), ('አንባቢያን ኢትዮጵያ በተደጋጋሚ ጥሪው', 1), ('ኢትዮጵያ በተደጋጋሚ ጥሪው ደርሷት', 1), ('በተደጋጋሚ ጥሪው ደርሷት ልትታደመው', 1), ('ጥሪው ደርሷት ልትታደመው ያልቻለችው', 1), ('ደርሷት ልትታደመው ያልቻለችው የአለም', 1), ('ልትታደመው ያልቻለችው የአለም የእግር', 1), ('ያልቻለችው የአለም የእግር ኳስ', 1), ('የአለም የእግር ኳስ ዋ', 1)]\n",
            "\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*1.2 Calculate probabilities of n-grams and find the top 10 most likely n-grams for all n.*"
      ],
      "metadata": {
        "id": "zW0QF72hnjPF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Calculating total count of each counts\n",
        "unigram_count = sum(unigram_freq.values())\n",
        "bigram_count = sum(bigram_freq.values())\n",
        "trigram_count = sum(trigram_freq.values())\n",
        "fourgram_count = sum(fourgram_freq.values())\n",
        "\n",
        "# Calculating probablities for each grams\n",
        "def unigramProbablity(unigram):\n",
        "  return unigram_freq[unigram] / unigram_count\n",
        "\n",
        "def bigramProbablity(bigram):\n",
        "  first_word = bigram.split()[0]\n",
        "  return bigram_freq[bigram] / unigram_freq[first_word]\n",
        "\n",
        "def trigramProbablity(trigram):\n",
        "  first_two_words = \" \".join(trigram.split()[:2])\n",
        "  return trigram_freq[trigram] / bigram_freq[first_two_words]\n",
        "def fourgramProbablity(fourgram):\n",
        "  first_three_words = \" \".join(fourgram.split()[:3])\n",
        "  return fourgram_freq[fourgram] / trigram_freq[first_three_words]\n",
        "\n",
        "# Calculate the probabilities of each grams(top ten)\n",
        "top_ten_unigram = sorted(unigram_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "top_ten_bigram = sorted(bigram_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "top_ten_trigram = sorted(trigram_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "top_ten_fourgram = sorted(fourgram_freq.items(), key=lambda x: x[1], reverse=True)[:10]\n",
        "\n",
        "# Print the top 10 most likely n-grams for all ngram\n",
        "print(\"Top 10 Unigrams: \", top_ten_unigram)\n",
        "print(\"Top 10 Bigrams: \", top_ten_bigram)\n",
        "print(\"Top 10 Trigrams: \", top_ten_trigram)\n",
        "print(\"Top 10 Fourgrams: \", top_ten_fourgram)\n",
        "\n",
        "# Calculating the probability of the top n-grams\n",
        "top_ten_unigram_prob = [(unigram, round(unigramProbablity(unigram),2)) for unigram, freq in top_ten_unigram]\n",
        "top_ten_bigram_prob = [(bigram, round(bigramProbablity(bigram),2)) for bigram, freq in top_ten_bigram]\n",
        "top_ten_trigram_prob = [(trigram, round(trigramProbablity(trigram),2)) for trigram, freq in top_ten_trigram]\n",
        "top_ten_fourgram_prob = [(fourgram, round(fourgramProbablity(fourgram),2)) for fourgram, freq in top_ten_fourgram]\n",
        "print(\"Top 10 Unigrams Probability: \", top_ten_unigram_prob)\n",
        "print(\"Top 10 Bigrams Probability: \", top_ten_bigram_prob)\n",
        "print(\"Top 10 Trigrams Probability: \", top_ten_trigram_prob)"
      ],
      "metadata": {
        "id": "4TDud4JfPaLg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "28e25072-4b5c-42d8-d9d9-b02c0fda451f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 10 Unigrams:  [('ነው', 324514), ('ላይ', 205491), ('ውስጥ', 104513), ('ወደ', 88689), ('ግን', 86765), ('ጋር', 75879), ('ነበር', 73773), ('እና', 66925), ('ነገር', 64174), ('ጊዜ', 63284)]\n",
            "Top 10 Bigrams:  [('ዓ ም', 32697), ('ነገር ግን', 14568), ('ብቻ ሳይሆን', 9897), ('ኤ አ', 8628), ('ማለት ነው', 8395), ('እ ኤ', 8285), ('ብቻ ነው', 7077), ('አዲስ አበባ', 6976), ('ምክር ቤት', 6907), ('በአዲስ አበባ', 6535)]\n",
            "Top 10 Trigrams:  [('እ ኤ አ', 8227), ('2010 ዓ ም', 3547), ('2011 ዓ ም', 3037), ('ቀን 2010 ዓ', 3029), ('ቀን 2011 ዓ', 2701), ('ዓ ም ጀምሮ', 2125), ('2007 ዓ ም', 2110), ('2008 ዓ ም', 2040), ('2012 ዓ ም', 1921), ('ነው ነገር ግን', 1884)]\n",
            "Top 10 Fourgrams:  [('ቀን 2010 ዓ ም', 3028), ('ቀን 2011 ዓ ም', 2700), ('ቀን 2008 ዓ ም', 1754), ('ቀን 2007 ዓ ም', 1715), ('ቀን 2012 ዓ ም', 1706), ('ሚኒስትር ዓብይ አህመድ ዶር', 1075), ('አመለካከት ብቻ የሚያንፀባርቅ መሆኑን', 944), ('የጸሐፊውን አመለካከት ብቻ የሚያንፀባርቅ', 923), ('ጽሑፉ የጸሐፊውን አመለካከት ብቻ', 919), ('የአዲስ አበባ ከተማ አስተዳደር', 777)]\n",
            "Top 10 Unigrams Probability:  [('ነው', 0.02), ('ላይ', 0.01), ('ውስጥ', 0.0), ('ወደ', 0.0), ('ግን', 0.0), ('ጋር', 0.0), ('ነበር', 0.0), ('እና', 0.0), ('ነገር', 0.0), ('ጊዜ', 0.0)]\n",
            "Top 10 Bigrams Probability:  [('ዓ ም', 0.99), ('ነገር ግን', 0.23), ('ብቻ ሳይሆን', 0.19), ('ኤ አ', 0.92), ('ማለት ነው', 0.27), ('እ ኤ', 0.92), ('ብቻ ነው', 0.13), ('አዲስ አበባ', 0.31), ('ምክር ቤት', 0.58), ('በአዲስ አበባ', 0.71)]\n",
            "Top 10 Trigrams Probability:  [('እ ኤ አ', 0.99), ('2010 ዓ ም', 1.0), ('2011 ዓ ም', 1.0), ('ቀን 2010 ዓ', 0.98), ('ቀን 2011 ዓ', 0.98), ('ዓ ም ጀምሮ', 0.06), ('2007 ዓ ም', 1.0), ('2008 ዓ ም', 1.0), ('2012 ዓ ም', 1.0), ('ነው ነገር ግን', 0.97)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "IdpLfgYTOEY_"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iLNSId8rx0Yg"
      },
      "execution_count": 4,
      "outputs": []
    }
  ]
}